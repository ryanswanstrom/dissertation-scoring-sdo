\documentclass[SDSUThesis.tex]{subfiles} 
\begin{document}

\section{MEASURING A SDO}

Anything can be measured \cite{Hubbard2010}.

A metric can be defined as the science of indirect measurement.
    The following are some examples of metrics that can be collected 
    about source code:
    \begin{itemize}
        \item SLOC - The number of Source Lines of Code 
        \item NOM - The Number of Methods per class
        \item Complexity - A numerical measure of the code complexity,
            some common examples are McCabe \cite{McCabe1976} and 
            Halstead \cite{Halstead1977}
        \item Design - The amount of coupling and cohesion present 
        in the software code
        \item Source Code Analysis - Tools that determine whether 
        code adheres to specified set of rules. Common 
        examples are PMD and findbugs \cite{PMD, Findbugs}.
    \end{itemize}

Data Driven Software Engineering not Data Driven Software Development

Performance indicators can be crucial measurements
within any business setting, and an SDO is no exception. Many
SDOs struggle to determine the correct indicators to track and
how to track them.  
The differences between the indicators will be explored and
possible measures for each indicator in an SDO will be
presented.  The 4 different types of indicators are:
\begin{description}
  \item[RI (Result Indicator)] - what has been done
  \item[KRI (Key Result Indicator)] - how you have done
  \item[PI (Performance Indicator)] - what to do
  \item[KPI (Key Performance Indicator)] - what to do to dramatically increase performance
\end{description}

More information on the indicators can be found
in chapter 1 of \cite{parmenter2010}
as well as \cite{florac1999,kaplan1992}.

\subsection{RESULT INDICATORS FOR SDO}
    This section will cover the potential result indicators for an SDO.
    
\subsection{KEY RESULT INDICATORS FOR SDO}


\subsection{PERFORMANCE INDICATORS FOR SDO}
    This section will cover the potential performance indicators for an SDO.
    
    
\subsection{KEY PERFORMANCE INDICATORS FOR SDO}
    

\subsection{BALANCED SCORECARD}

A common technique for organization to measure themselves is a balanced scorecard.
A \textit{balanced scorecard} must contain the following
characteristics.
\begin{itemize}
  \item Financial 
  \item Customer Focus
  \item Environment/Community
  \item Internal Process
  \item Employee Satisfaction
  \item Learning and Growth
\end{itemize}

Balanced scorecards are great for displaying the important information about
and organization.  However, a balanced scorecard does not specify what
exactly needs to be tracked.  It is also not specific to an SDO and 
it does not produce a single number.

This info comes from \cite{parmenter2010}.

\subsection{POSSIBLE DATA POINTS FOR LEVEL OF EFFORT}

\begin{description}
    \item[Actual Development Hours] Actual Hours Spent on development
    \item[Estimated Development Hours]  Initial Hours estimated for a project, this will commonly be different from the actual development hours
    \item[Source Lines Of Code (SLOC)]  This is count of the total number of lines of source code
    \item[Modified Lines Of Code] This is a count of the number of modified lines of source code. This number is a sum of the deleted, added, and modified lines of source code.
\end{description}

According to Putnam and Myers in \cite{Putnam2013}, the 5 core measurements for managing software
projects are:

\begin{enumerate}
    \item \textbf{Quantity of function} usually measured in terms of size (such as source lines of code or function points), that ultimately execute on the computer
    \item \textbf{Productivity} as expressed in terms of the functionality produced for the time and effort expended
    \item \textbf{Time} the duration of the project in calendar months
    \item \textbf{Effort} the amount of work expended in person-months
    \item \textbf{Reliability} as expressed in terms of defect rate (or its reciprocal, mean time to defect)
\end{enumerate}
However, these measurements don't focus on the entire SDO. They say nothing about the availablity of the software infrastructure or the satisfaction of the users.

\begin{description}
  \item[Time] This measurement can be hours, days, weeks, or months.  the time increment does not matter as long as it is consistent.
  \item[Effort] This measurement is person-months, person-weeks, or person-days.
  \item[Quality] This measurement is the defect rate (defects per time period).
  \item[Amount of Work] This measurement has the same units as Effort above. 
  \item[Process Productivity] look into this a bit further
  \item[Function Points] find a definition and a comparison with story points
  \item[Story Points] Look in some agile book
\end{description}

Chapter 7 of \cite{Putnam2013} contains some equations to calculate and relate
these measures. Those equations will be studied and evaluated.

Antolic in \cite{Antolic2008} demostrates some ways to measure KPIs for the  software development process.

\subsection{MEASURING OTHER ASPECTS OF AN SDO}

It is important to note that software departments do not just
develop software.  The department has many other duties
including: deploying software, installing server hardware/software,
writing documentation, surveying users, and other things.

\subsection{COMBINING THE MEASURES TO FORM MPI}

How can the PIs, RIs, KRIs, and KPIs be combined to form a single
value called an MPI (Master Performance Indicator)?  The field
of sports analytics also has numerous techniques for combining
multiple indicators to produce a single number \cite{Cervone2014}.


\end{document}