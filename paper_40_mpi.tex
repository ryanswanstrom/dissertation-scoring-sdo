\documentclass[SDSUThesis.tex]{subfiles} 
\begin{document}

\section{MASTER PERFORMANCE INDICATOR (MPI)}

    Software development organizations struggle to measure overall performance.  
    The Master Performance Indicator (MPI) is an algorithm to provide a single 
    number score to measure the performance of a software development organization. 
    It works by statistically analyzing the past performance of the 
    organization and using that information to score an organization 
    on current performance.  MPI focuses on the following 
    elements of a software development organization: \textit{quality}, 
    \textit{availability}, \textit{satisfaction}, \textit{schedule},
    and \textit{requirements}. A separate MPI
    score is calculated for each element and 
    then aggregated together to form an overall 
    MPI score.  A new MPI score will be calculated based
    upon the selection of a given time period (weekly, monthly, quarterly).
    \textbf{MPI is not meant to be comparative between
    organizations, but to measure the amount of increase or decrease
    a single organization exhibits across elements}.  MPI is made to be easily 
    expandable to other elements if desired.
    
    The scores for MPI will range from -1, indicating the worst 
    performance, all the way to +1, indicating perfection.
    A score of 0 is an indication of meeting the basic expectations. 
    A negative score indicates under-performance and a 
    positive score indicates over-performance.   Here are some 
    examples. An MPI score of 0.35 means the organization is 
    performing 35\% better than expected.  Conversely, a score 
    of -0.15 means an organization is performing 15\% worse than expected.  

    Below are the attributes of the MPI scoring.
    \begin{itemize}
        \item The range of scores must have equal values above and below 0
        \item The minimum score must equate to the worst possible 
            performance, however that is defined
        \item Similarily, the maximum score must equate to the best possible performance.  
        \item A score of 0 must be average (or expected) performance
        \item All individual elements must have the same scoring range
    \end{itemize}
            
    As long as those 5 features are met, the range can be anything.  
    The range of $[-1,1]$ was chosen because it is easy to scale 
    to a different range such as $[-10,10]$ or $[-100,100]$.  
    It maybe makes sense to use variables for the range.  
    The formulas are designed to fall in the range $[-100,100]$.  
    Thus scaling can be applied to obtain values in any appropriate range. 
    The scaling is denoted with the variable $k$.  The scale will be the same
    for all 5 elements.
    
    \subsection{ELEMENTS OF MPI}
        The MPI score consists of data collected from five
        different elements of an SDO.  
        \begin{enumerate}
            \item Quality
            \item Availability
            \item Satisfaction
            \item Schedule
            \item Requirements
        \end{enumerate}
        These five elements will be outline in the next sections.
        
        \subsubsection{QUALITY}
            Measuring quality is a crucial part of accessing 
            software development results.  
            Poor quality means time, money, and resources are spent 
            fixing the problems. As a result, new features are not being
            created. One of the key indicators of software quality 
            is defects.  Thus, it is important
            to measure the number of defects associated with a software 
            release.  The following is the necessary data to collect
            and an algorithm to calculate
            the quality score of software being released. 
            
            \paragraph{QUALITY DATA}
                In order to properly score the quality of an SDO,
                certain data needs to be obtained in order to measure
                performance. Table \ref{tab:qualitydata} identifies
                the columns of data that will be used to create
                a score for the quality element of MPI.  
                Each column is classified as \textit{required} or
                \textit{optional}.  That is to allow some flexibility
                in the model for organizations that collect
                varying amounts of data.
                
                \begin{longtable}{@{}l rr rr}
                    % pairs: absolute number (percentage)
                    
                    \toprule%
                     \centering%
                     {\bfseries Column Name}
                     & {\bfseries Data Type}
                     &  \\
                    
                    \cmidrule[0.4pt](r{0.125em}){1-1}%
                    \cmidrule[0.4pt](lr{0.125em}){2-2}%
                    \cmidrule[0.4pt](l{0.125em}){3-3}%
                    % \midrule
                    \endhead
                    
                    Application ID & String (factor) & Required \\
                    \myrowcolour%
                    Frequency Date & Date & Required \\
                    Development Effort & Integer & Required \\
                    \myrowcolour%
                    Testing Effort & Integer & Optional \\ 
                    SIT Defects & Integer & Optional \\ 
                    \myrowcolour%
                    UAT Defects & Integer  & Optional \\ 
                    PROD Defects & Integer  & Required \\
                    
                    \bottomrule
                    
                    \caption{QUALITY DATA NEEDED FOR MPI}
                    \label{tab:qualitydata}
                \end{longtable}
                
                The development and testing effort can come from any of 
                the following choices for effort. It is possible
                that other measures will work for effort.
                \begin{description}
                    \item[Actual Time] This number is a representation of the 
                        total amount of time spent on a project.  This number
                        can be measured in any unit of time: hours, days, weeks,
                        etc.  Actual time can be applied to development or testing
                        effort.
                    \item[Estimated Time] This number is a representation of the 
                        initial estimated amount of time spent on a project.  This number
                        can be measured in any unit of time: hours, days, weeks,
                        etc.  Estimated time can be applied to development or testing
                        effort.  It is common for the estimated and actual times
                        to be diffent.
                    \item[Source Lines Of Code (SLOC)]  This number is the count of 
                        the total number of lines of source code for a project. 
                        Obviously, 
                        this item only counts as a level of
                        effort for development unless coding in used to generate
                        automated test cases. \footnote{Automated testing is the
                        process of creating software to automatically run tests
                        against other software.  The adoption of automated testing
                        is varied and it is not a solution in all cases 
                        \cite{Ramler2006}. }
                    \item[Modified Lines Of Code] This number is a count of the number 
                        of modified lines of source code. Modified lines is 
                        defined as the number of deleted, added, and modified 
                        lines of source code.  This number is different from above
                        since it does not include all the lines of source code.  Similar
                        to above, this number makes more sense for development effort.
                    \item[Test Cases] A test case is a step or series of steps followed
                        to validate some expected outcome of software.  Organizations
                        will create a number of test cases to be validated for a
                        software system.  The number of such test cases could
                        be used as a level of testing effort.
                \end{description}
            
            \paragraph{QUALITY FORMULA}
                The first step in creating a score for the quality
                element is analysis of the historical data.  The historical
                data is all quality data collected before  a given point
                in time.  Some common historical cutoffs are the current date
                or the end of the previous fiscal year.  Then a mathematical
                model to predict PROD Defects will be produced.  In statistical
                terms, the response is \textit{PROD Defects} and the predictors
                are: \textit{UAT Defects}, \textit{SIT Defects}, 
                \textit{Testing Effort}, and \textit{Development Effort}.  
                Some of the following strategies will be employed to find 
                a reasonable model.
                \begin{itemize}
                    \item Removal of outliers and/or influential points
                    \item Linear Regression
                    \item Stepwise Regression
                    \item Ridge Regression for suspected multicolinearity
                \end{itemize}
                
                Once a model has been found, it will be labeled as $f$ and it
                will not change.  The function $f$ can be the same for all 
                Application IDs or it can be different for each Application ID
                or any combination of Application IDs.   It serves as the 
                quality baseline for MPI. 
                All future quality scores will be dependent upon the original
                $f$.  Once set, the model will not change.
                
                After the model $f$ has been determined, it is time
                to calculate the quality score for each application ID
                within the given time period.  The quality score
                for each Application ID can be calculated as follows.
                
                \begin{displaymath}
                   S_{1_i} = \left\{
                     \begin{array}{lr}
                       \text{where } f_i \geq d_i & :  \frac{f_i - d_i}{f_i} \times k  \\
                       \text{where } d_i > f_i  & : \frac{f_i-d_i }{6\sigma_i} \times k
                     \end{array}
                   \right] \text{   , calculate quality score for each app $i$}
                \end{displaymath} 
                where
                \begin{itemize}
                    \item $S_{1_i}$ is the quality score for Application ID $i$
                    \item $n$ is the number of Application IDs
                    \item $d_i$ is the actual PROD defects
                    \item $f_i$ is the function to predict PROD defects for Application $i$ based upon 
                        \textit{UAT Defects}, \textit{SIT Defects}, \textit{Testing Effort}, 
                        and \textit{Development Effort}
                    \item $6\sigma$ 6 times an estimate of the standard deviation of the 
                        population using function $f_i$ above
                \end{itemize}
                
                Then the overall quality score is calculated as below.
                
                \[
                    S_{1} = \sum\limits^n_{i=1} w'_i S_{1_i} \text{ where } \sum\limits^n_{i=1} w'_i = 1
                \]
                where
                \begin{itemize}
                    \item $S_1$ is the combined quality score for all Application IDs, 
                    a weighted average
                \end{itemize}
                
                Then $S_1$ represents the quality score for that given time period.
        


        \subsubsection{AVAILABILITY}
            All the new requirements and great quality do not matter if the software is not available.
            All the new features and great quality do not matter if the software is not available.  Thus it
            is essential to set an expected Service Level Agreement (SLA)\footnote{For an SDO, an SLA is a 
            contract specifying the amount of time software will be available during a
            given time period. } and measure 
            performance against that SLA.  The following section will outline to data needed to properly
            calculate an SLA and the data needed to calculate the MPI score for availability.
            
            Special Note: The Service ID for availability does not have to be the same
            as the Application ID for quality or any of the other elements.  Some 
            organizations have a one-to-one mapping between Applications being developed
            and services being deployed.  Others have more complex sceranios that require
            multiple applications to be combined to form a service.  Then the availability
            of the system is tracked.
            
            \paragraph{AVAILABILITY DATA}
                Table \ref{tab:availdata} identifies the necessary data to calculate
                the MPI element score for availability.  Notice the three optional 
                fields: \textit{Uptime}, \textit{Scheduled Downtime}, and 
                \textit{Unscheduled Downtime}; they are optional because they can be
                used to calculated the \textit{Percent Uptime}.  The \textit{Percent Uptime}
                is the important value for the MPI schedule score.  Here are the two common
                approaches for calculating percent uptime:
                
                The preferred method
                \[
                    \text{Percent Uptime} = \frac{\text{Uptime}}{\text{Uptime + Scheduled Downtime + Unscheduled Downtime}}
                \]
                and the alternative method
                \[
                    \text{Percent Uptime} = \frac{\text{Uptime}}{\text{Uptime + Unscheduled Downtime}}
                \]
                The only difference is the removal of scheduled downtime from 
                the calculation.  The calculation approach is typically specified in
                the contract associated with the SLA.  Thus, the Percent Uptime is important
                and it can either be supplied in the data or calculated from the 
                optional fields.
            
            
                \begin{longtable}{@{}l rr rr}
                    \toprule%
                     \centering%
                     {\bfseries Column Name}
                     & {\bfseries Data Type}
                     &  \\
                    
                    \cmidrule[0.4pt](r{0.125em}){1-1}%
                    \cmidrule[0.4pt](lr{0.125em}){2-2}%
                    \cmidrule[0.4pt](l{0.125em}){3-3}%
                    % \midrule
                    \endhead
                    
                    Service ID & String  & Required \\
                    \myrowcolour%
                    Frequency Date & Date & Required \\
                    Uptime & Float & Optional \\
                    \myrowcolour%
                    Scheduled Downtime & Float & Optional \\
                    Unscheduled Downtime & Float  & Optional \\
                    \myrowcolour%
                    Percent Uptime & Float & Required \\
                    Expected Percent Uptime & Float & Required \\
                    
                    \bottomrule
                    
                    \caption{AVAILABILITY DATA NEEDED FOR MPI}
                    \label{tab:availdata}
                \end{longtable}
            
            \paragraph{AVAILABILITY FORMULA}
                The formula for availability is more straightforward than the quality formula.
                It does not include any analysis of the historic data.  That lack of historical
                analysis is avoided since the SLA provides an existing baseline to measure 
                against.  The following formula is simply a percentage the SLA was exceeded
                or missed. 
                
                \begin{displaymath}
                   S_{2_i} = \left\{
                     \begin{array}{lr}
                       \text{where } A_{a_i} \leq A_{e_i} & : \left[ \frac{A_{a_i} - A_{e_i}}{A_{e_i}}\times k \right] \\
                       \text{where } A_{a_i} > A_{e_i}  & : \left[ \frac{A_{a_i} - A_{e_i} }{1-A_{e_i}}\times k \right]
                     \end{array}
                   \right. \text{   , calculate availability score for each app $i$}
                \end{displaymath}
                
                where
                
                \begin{itemize}
                    \item $A_{a_i}$ actual availability for System ID $i$
                    \item $A_{e_i}$ expected availability for System ID $i$
                \end{itemize}
                
                Then the overall availability score is calculated as below.
                
                \[
                    S_{2} = \sum\limits^n_{i=1} w'_i S_{2_i} \text{ where } \sum\limits^n_{i=1} w'_i = 1
                \]
                
        \subsubsection{SATISFACTION}
            The satisfaction of users, customers, and/or business partners is 
            the third element to be measured.  This element is important because 
            in an established business, retaining customers is less expensive
            than attracting new customers \cite{Aulet2013}.  
            Depending upon the type of SDO,
            the customers may be internal or external to the organization.  For
            the remainder of this section, the term customer will be used
            to represent any person who is responsible for guidance, decision-making
            or use of the software.  The term customer can refer to a: user, paying or nonpaying
            customer, internal or external business partner, or any other person deemed influential
            to the development of the software.
            
            \textit{If one element of MPI was to be rated as the most important, satisfaction
            would be it.}  
            Without satisfied customers, the rest of the measures do not matter.
            For example, having a quality
            application that is always available does not matter if the
            application is not what the customer wants.  
            
            Surveys are used to measure satisfaction for MPI.  A series of statements will
            be presented to all or a subset of the customers.  Any customer that chooses
            to respond to the survey is considered a respondent.  A respondent can rate
            statements based upon a Likert Scale\footnote{"The Likert Scale presents 
            respondents with a series of (attitude) dimensions, which fall along a
            continuum." \cite{Cowles2015}} with a numerical response where the 
            minimum value indicates maximum
            disagreement and the maximum value indicates
            the maximum agreement. Common rating scales would be
            from 1 to 5 or from 1 to 3.  An example survey can be seen in Table 
            \ref{tab:samplesurvey}.
            
            
            \begin{longtable}{@{}l rr rr}
                \toprule%
                 \centering%
                 {\bfseries ID}
                 & {\bfseries Statement}
                 & {\bfseries Disagree}
                 & {\bfseries Neutral}
                 & {\bfseries Agree}  \\
                
                \cmidrule[0.4pt](r{0.125em}){1-1}%
                \cmidrule[0.4pt](lr{0.125em}){2-2}%
                \cmidrule[0.4pt](l{0.125em}){3-3}%
                \cmidrule[0.4pt](l{0.125em}){4-4}%
                \cmidrule[0.4pt](l{0.125em}){5-5}%
                % \midrule
                \endhead
                
                1 & I find the software easy to use.  & & & \\
                \myrowcolour%
                2 & I would recommend this software to others. & & & \\
                3 & The software makes me more productive. & & & \\
                \myrowcolour%
                4 & I am happy with this software. & & & \\
                
                \bottomrule
                
                \caption{SAMPLE SURVEY FOR SATISFACTION}
                \label{tab:samplesurvey}
            \end{longtable}
            
            \paragraph{ISSUES WITH SURVEYS}
                Surveys present a number of challenges that need to be presented and briefly
                discussed.  Here are some of the issues that need to be addressed when
                using surveys. 
                
                \begin{description}
                \item[Text] \hfill \\
                    The specific text used in the questions or statments
                    is very important.  The text cannot be too vague.  Also, the text
                    must be clear enough to eliminate misinterpretation. Survey
                    questions must be complete and not include gaps.  For example, if
                    an age range is presented, it must include all possible ages.  These
                    are just some of the difficulties with getting the text correct
                    in surveys. 
                \item[Number and Ordering] \hfill \\
                    The number of questions is important.  Too many questions and the 
                    respondents will lose interest and begin responding without the
                    adequate attention needed.  Plus, if the survey is too long there
                    is the risk of quitting before completion.  A short survey might
                    not cover the adequate amount of material.  Both short and long
                    surveys run the risk of providing inaccurate responses.  After
                    determining the best number of questions, the ordering of the questions
                    is important.  Previous survey questions can have an unintended 
                    impact on responses.  Thus, the ordering of questions needs to be
                    addressed. 
                \item[Sampling] \hfill \\
                    Next is the issue of sampling.  Not every customer can be surveyed, so 
                    sample sets os customers need to be presented with a survery.  
                    In the case of MPI, there are 2 possible scenarios for sampling.  
                    \begin{description}
                    \item[First]
                    When an SDO is part of a larger organization, there typically is
                    a small number of business partners that help to guide and 
                    direct the work performed by the SDO.  In this case, the business 
                    partners might be the the ones offering survey responses and they 
                    should all be willing to respond.  Thus, those business partners 
                    represent the entire population, and the surveys should result in 
                    a 100\% response rate which is technically a census.  
                    The only bias that will be present here is the bias of the business 
                    partners and sampling cannot control for that.
           
                    \item[Second] End-users will be surveyed for satisfaction. Obviously, the 
                    entire population cannot be surveyed, so a probability sample should 
                    be randomly created. Even then, bias will be present.  
                        \begin{itemize}
                            \item Not all users will respond.  This is because survey 
                                respondents tend to sit at the extremes of either 
                                satisfied or dissatisfied.  Thus the results will tend 
                                to indicate that separation. 
                            \item  Even with probability sampling it is possible to miss 
                                entire groups of population members. For example consider a 
                                banking application such as a savings account, a survey would 
                                most likely be presented online and it would have a coverage 
                                bias due the exclusion of savings account holders that 
                                do not bank online.
                            \item A selection bias can occur when some members of the 
                                population have a higher probability of inclusion in 
                                the sampling frame than others.  One example could be 
                                a user with multiple savings accounts.  The selection 
                                bias is typically easy to avoid if the bias is 
                                identified.  Weighting is a common solution for selection bias. 
                        \end{itemize}
                       
                    \end{description}
                
                \end{description}
                
                
           
            For more on creating appropriate surveys, see \cite{Snijkers2013} by Snijkers,
            Haraldsen, Jones, and Willimack. In the book, Snijkers et al. present a framework
            named generic statistical business process model (GSBPM) for conducting surveys
            in a business or organizational setting.  GSBPM covers the issues above as well
            as a few more issues such as response storage and risks.  Also, Cowles and Nelson
            provide another good resource for preparing and conducting surveys 
            \cite{Cowles2015}.  They even include an entire chapters on both writing 
            survey questions and survey errors. 
            
            \paragraph{SATISFACTION DATA}
                Once the surveys have been distributed and the results collected, Table
                \ref{tab:satisfactiondata} displays the data that needs to be collected 
                in order to calculate the satisfaction element score for MPI.
                \begin{longtable}{@{}l rr rr}
                    \toprule%
                     \centering%
                     {\bfseries Column Name}
                     & {\bfseries Data Type}
                     &  \\
                    
                    \cmidrule[0.4pt](r{0.125em}){1-1}%
                    \cmidrule[0.4pt](lr{0.125em}){2-2}%
                    \cmidrule[0.4pt](l{0.125em}){3-3}%
                    % \midrule
                    \endhead
                    
                    Question ID & String  & Required \\
                    \myrowcolour%
                    Question Text & String  & Optional \\
                    Respondent ID & String & Optional \\
                    \myrowcolour%
                    Frequency Date & Date & Required \\
                    Response & Integer & Required \\
                    \myrowcolour%
                    Response Date & Date & Optional \\
                    Application ID & String & Optional \\
                    
                    \bottomrule
                    
                    \caption{SATISFACTION DATA NEEDED FOR MPI}
                    \label{tab:satisfactiondata}
                \end{longtable}
            
            \paragraph{SATISFACTION FORMULA}
                After collecting the necessary survey data from Table \ref{tab:satisfactiondata},
                calculating the score is rather straight forward.
                The scores for each question are averaged and then those
                values are averaged together.  If some survey questions
                are more important than others, the formula could be
                easily modified to include weighting.  
            
                First the score for each question needs to be calculated.
                
                \[
                    S_{3_i} = \sum^n_{i=1}\left( k \times \frac{ \sum^m_{j=1}a_{ij}-\frac{min + max}{2}}{m} \right)
                \]
                
                \begin{itemize}
                    \item $a_{ij}$ answer to question $i$ for respondent $j$
                    \item $n$ number of questions
                    \item $m$ number of respondents
                    \item $min$ minimum score for a question
                    \item $max$ maximum score for a question
                \end{itemize}
                
                Then the satisfaction score is calculated as below.  Use a weighted average
                to combine the question scores.
                
                \[
                    S_{3} = \sum\limits^n_{i=1} w'_i S_{3_i} \text{ where } \sum\limits^n_{i=1} w'_i = 1
                \]

        \subsubsection{SCHEDULE}  
            Delivery of software in a timely manner is an essential part of being a 
            successful SDO.  Being able to meet scheduled deadlines is a sign of accurate
            estimation and planning.  Drastically missing deadlines is a sign of an SDO
            with a process that needs refinement.  Studies have shown that 
            software projects exceed the estimates by an average of
            30\% \cite{Jorgensen2014}.  Thus it is important to score SDOs on accurate
            schedule adherence. Without tracking and measuring schedule adherence, it will
            not improve.  
            
            \paragraph{SCHEDULE DATA}
            
                \begin{longtable}{@{}l rr rr}
                    \toprule%
                     \centering%
                     {\bfseries Column Name}
                     & {\bfseries Data Type}
                     &  \\
                    
                    \cmidrule[0.4pt](r{0.125em}){1-1}%
                    \cmidrule[0.4pt](lr{0.125em}){2-2}%
                    \cmidrule[0.4pt](l{0.125em}){3-3}%
                    % \midrule
                    \endhead
                    
                    Application ID & String  & Required \\
                    \myrowcolour%
                    Frequency Date & Date & Required \\
                    Scheduled Start Date & Date & Required \\
                    \myrowcolour%
                    Scheduled Finish Date & Date & Required \\
                    Actual Start Date & Date  & Optional \\
                    \myrowcolour%
                    Actual Finish Date & Date  & Required \\
                    
                    \bottomrule
                    
                    \caption{SCHEDULE DATA NEEDED FOR MPI}
                    \label{tab:sched}
                \end{longtable}
                    
            \paragraph{SCHEDULE FORMULA}
    
                The formula for schedule is based upon past performance.  Of the 422 projects
                scheduled since June 2013, only 45 projects had an estimated start date, estimated
                finish date and an actual finish date.  Of those 45 projects; 20 finished exactly on time,
                9 finished early and 16 finished late.  
                
                The first step of the formula is finding the percentage the schedules were missed for 
                historical projects.  The calculation treats over- and under-estimating the schedule
                the same.  The same penalty is applied in both cases.  For example, being 15\% late
                will result in the same score as being 15\% early. Perform this calculation
                only for projects that did not exactly meet the estimated finish date.
                
                \begin{displaymath}
                    \Delta_i = \left| \frac{F_{a_i} - F_{s_i}}{ F_{s_i} - B_{s_i} + 1} \right|
                \end{displaymath}
                
                Find the average of the $\Delta_i$'s.  This is the average percent of a missed
                schedule.  
                \begin{displaymath}
                   \bar{\Delta}  = \frac{\sum^n_{i=1}\Delta_i}{n}
                \end{displaymath}
                
                \textit{The formula for schedule is then a percentage above or below the $\Delta$.  
                The number is calculated for each project, and then averaged to form the schedule score.}
                
                After the $\bar{\Delta}$ is calculated, the following formulas are used to create the schedule scores
                for each project and then the averaged schedule score.
            
                \begin{displaymath}
                   S_{4_i} = \left\{
                     \begin{array}{lr}
                        \text{where } \Delta_i \geq 1 & : -1 \times 100 \\
                       \text{where }  \Delta_i \leq \bar{\Delta} & : \frac{\bar{\Delta} - \Delta_i}{\bar{\Delta}}   \times 100  \\
                       \text{where } \Delta_i > \bar{\Delta} & : \frac{\bar{\Delta} - \Delta_i}{1 - \bar{\Delta}} \times 100
                     \end{array}
                   \right] \text{   , calculate schedule score for each project $i$}
                \end{displaymath} 
        
                \[
                    S_{4} = \frac{\sum^n_{i=1} S_{4_i}}{n} \text{   , average the schedule scores}
                \]
                \begin{itemize}
                    \item $n$ is the number of projects
                    \item $F_{a_i}$ the actual finish date of project i
                    \item $F_{s_i}$ the scheduled finish date of project i
                    \item $B_{s_i}$ the scheduled beginning date of project i
                    \item $\Delta_i$ the percent the schedule was missed
                    \item $\bar{\Delta}$ is the average percent RT misses schedules, $\approx 26$
                    \item $S_{4_i}$ is the schedule score for project $i$
                \end{itemize}
    
    
            \paragraph{ALTERNATE APPROACH}
                The best possible score should be achieved
                when meeting the estimated date exactly.  The maximum score
                should come from the best estimate.  Then given historical
                release data, it is easy to determine an 
                average $\Delta$ between the actual and the estimated.  
                Finishing a project within that $\Delta$ should result 
                in a positive score.  Outside the $\Delta$ results in
                negative scores.  For example, a project releasing
                one day early or one day late would receive the same score
                because in both cases the estimate was missed by one day.

%The score can be accomplished with the following 
%algorithm.
%\[
%    S_4 = \frac{\sum^n_{i=1} \left( C_{a_i} - C_{e_i} \right)}{n}
%\]
%\begin{itemize}
%\item $C_a$ actual number of days for application $i$
%\item $C_e$ estimated number of days for application $i$
%\end{itemize}


        \subsubsection{REQUIREMENTS}
            
            \paragraph{REQUIREMENTS DATA}
            
                \begin{longtable}{@{}l rr rr}
                    \toprule%
                     \centering%
                     {\bfseries Column Name}
                     & {\bfseries Data Type}
                     &  \\
                    
                    \cmidrule[0.4pt](r{0.125em}){1-1}%
                    \cmidrule[0.4pt](lr{0.125em}){2-2}%
                    \cmidrule[0.4pt](l{0.125em}){3-3}%
                    % \midrule
                    \endhead
                    
                    Application ID & String  & Required \\
                    \myrowcolour%
                    Frequency Date & Date & Required \\
                    Requirements Scheduled & Integer & Required \\
                    \myrowcolour%
                    Actual Requirements Released & Integer  & Required \\
                    
                    \bottomrule
                    
                    \caption{REQUIREMENTS DATA NEEDED FOR MPI}
                    \label{tab:req}
                \end{longtable}
            
            \paragraph{REQUIREMENTS FORMULA}
                Requirements are desired new features or enhancements 
                to a software product.  It is important to know how many requirements
                were scheduled to be completed versus how many actually got completed.  
                \[
                    S_5 = \frac{\sum^n_{i=1}\left( R_{a_i} - R_{e_i} \right)}{n}
                \]
                \begin{itemize}
                    \item $R_a$ actual requirements completed for application $i$
                    \item $R_e$ expected requirements completed for application $i$
                \end{itemize}
            

        \subsubsection{OVERALL MPI SCORE}
            In order to accomplish the single number score that MPI requires,
            the 5 element scores must be combined. The combination of the scores
            is a weighted average.  The weights can be set based upon the 
            priority of the SDO.  Thus, the overall MPI score is calculated as below.
            
            \[
                MPI =\sum\limits^n_{i=1} w_i S_i \text{ where } \sum\limits^n_{i=1} w_i = 1
            \]


    \subsection{CORRELATIONS IN MPI}
        It is possible that 2 or more of the 5 elements of MPI will be correlated.  This means that
        one of the elements can be predicted based upon the values of the other elements.  Although
        it is possible for correlation to occur between any of the elements, the satisfaction element
        is an obvious element which deserves attention due to the human involvement of the surveys. 
        If a schedule is missed or an important requirement dropped, that could have a large negative
        effect on the satisfaction surveys.  The same could be said of quality or availability with regard to 
        the satisfaction.  However, satisfaction is not the only potentially correlated element.  It is also
        possible that a decrease in quality could result in unexpected downtime which could have a
        negative result on availability.  Similarly, if requirements are added, it is possible the schedule
        will be negatively impacted.  Also, if requirements are dropped, the quality might suffer due
        to missing functionality.  
        
        It is impossible to know which or if correlations will always exist.  Thus it is necessary to
        check for correlations after determining element and overall MPI scores.  
        If correlation is determined, the element should not be dropped but rather be weighted less than
        the other elements.  This technique keeps the most data available but lessens the importance of
        the correlated element. 
        
    \subsection{SENSITIVITY OF MPI}
    \label{sub:sensitivity}
        
        Some simulations will be run with data from each given distribution.  Then the MPI scores
        will be analyzed.
        For more on sensitivity analysis in statistical modeling, see \cite{Saltelli2000}.

    \subsection{MPI COMPARED}
    
        \subsubsection{MPI VS. FOCUS AREAS OF SOFTWARE ANALYTICS}
    
            Earlier, in the introduction section \ref{subsub:softwareanalytics}, 3 main focus 
            areas  for software
            analytics were presented.  Table \ref{tab:focusareas} provides a explanation of how MPI addresses
            each focus area.  
            As can be seen, MPI clearly addresses the 3 main focus areas of software analytics.  MPI does not provide
            any mechanisms for improving the focus areas, but it provides a consistent mechanism to measure
            the focus areas. 
            
            \begin{longtable}{p{3cm}p{11cm}}
                \toprule%
                 \centering%
                 {\bfseries Focus Area}
                 & {\bfseries Why MPI?} \\
                
                \cmidrule[0.4pt](r{0.125em}){1-1}%
                \cmidrule[0.4pt](lr{0.125em}){2-2}%
                % \midrule
                \endhead
                
                User Experience & One of the 5 elements of MPI is satisfaction.  While not all of the questions focus solely on the user experience, the entire purpose of the survey is to determine if the user is satisfied
                with the software product. Does it have the correct features? Are new features added in a timely manner? Of course, specific survey questions can be created to focus solely on a certain user experience. \\
                \myrowcolour%
                Quality & Again, one of the 5 elements specifically focuses on quality.  MPI provides a single number
                to measure quality.  Therefore, it is easy to track changes in quality over time.  MPI does not address
                how to improve the quality, but without a consistent measurement, it would be impossible to determine the change in quality. \\
                Development Productivity & The combination of MPI elements, schedule and requirements, provide an 
                indication of development productivity. The schedule element measures the productivity
                related to estimated schedule. Similarly, the requirement element measures the amount of
                work actually being completed.  \\
                
                \bottomrule
                
                \caption{SOFTWARE ANALYTICS FOCUS AREAS AND MPI}
                \label{tab:focusareas}
            \end{longtable}
        
        
        \subsubsection{MPI VS. FOCUS AREAS OF SOFTWARE ANALYTICS}
            Also, section \ref{subsub:softwareanalytics} mentions 3 important questions that
            software analytics must address.  Table \ref{tab:questions} presents the 3 questions
            and a description of how MPI addresses that specific question.  It is clear
            that MPI addresses the questions.  MPI is a beneficial technique of software
            analytics when applied to software development organizations.
        
            \begin{longtable}{p{4cm}p{10cm}}
                % pairs: absolute number (percentage)
                
                \toprule%
                 \centering%
                 {\bfseries Question}
                 & {\bfseries Why MPI?} \\
                
                \cmidrule[0.4pt](r{0.125em}){1-1}%
                \cmidrule[0.4pt](lr{0.125em}){2-2}%
                % \midrule
                \endhead
                
                How much better is my model performing than a naive strategy, such as guessing? & MPI 
                provides consistency which may not exist without it.  Therefore, MPI removes the 
                guesswork of measuring a software development organization. \\
                \myrowcolour%
                How practically significant are the results? & The MPI score is consistent
                and easy to comprehend.  Thus comparison with past performance is quick 
                and simple.  This is a significant advantage for software 
                development organizations. \\
                How sensitive are the results to small changes in one or more of the inputs? & 
                The question was extensively addressed in section \ref{sub:sensitivity}.  It appears MPI is
                not overly sensitive to small changes in the inputs.\\
                
                \bottomrule
                
                \caption{IMPORTANT QUESTIONS FOR SOFTWARE ANALYTICS AND MPI}
                \label{tab:questions}
            \end{longtable}

\end{document}